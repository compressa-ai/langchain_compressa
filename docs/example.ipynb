{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressa\n",
    "\n",
    "Compressa — это платформа, которая предлагает..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "y8ku6X96sebl"
   },
   "outputs": [],
   "source": [
    "from langchain_compressa import CompressaEmbeddings\n",
    "from langchain_compressa import ChatCompressa\n",
    "from langchain_compressa import CompressaRerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Установка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# установка пакета\n",
    "!pip install langchain-compressa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройка переменных окружения\n",
    "\n",
    "Убедитесь, что у вас установлена следующая переменная окружения:\n",
    "\n",
    "- COMPRESSA_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"COMPRESSA_API_KEY\"] = \"ваш_ключ_тут\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример реализации RAG пайплайна с помощью Langchain Compressa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG (Retrieval Augmented Generation) - это метод работы с большими языковыми моделями, когда в контекст запроса к языковой модели \n",
    "программно добавляется дополнительная информация, на основе которой языковая модель может дать пользователю более полный и точный ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#установите дополнительные необходимые пакеты\n",
    "!pip install langchain langchain_core langchain_community langchain_chroma bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_compressa import CompressaEmbeddings, ChatCompressa, CompressaRerank\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPRESSA_API_KEY = os.getenv('COMPRESSA_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#определим llm и embedding\n",
    "compressa_embedding = CompressaEmbeddings(api_key=COMPRESSA_API_KEY)\n",
    "llm = ChatCompressa(api_key=COMPRESSA_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#определим загрузчик документов и получим документы langchain.\n",
    "#здесь может быть использован любой из доступных загрузчиков.\n",
    "loader = WebBaseLoader(\"https://ru.wikipedia.org/wiki/Архитектура_фон_Неймана\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#определим text_splitter и разобъём документы на чанки\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=100, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#определим text_splitter и разобъём документы на чанки\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=100, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загрузим чанки документов в vectorstore и определим retriever\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=compressa_embedding)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#определим реранкер для использования в цепочке после извлечения документов\n",
    "compressor = CompressaRerank(api_key=COMPRESSA_API_KEY)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#определим Prompt для получения ответов на вопросы пользователя исходя из только контекста а не предыдущих знаний\n",
    "system_template = f\"\"\"Ты помощник по вопросам-ответам. \n",
    "Используй следующую контекстную информацию, чтобы ответить на вопрос. \n",
    "Если в контексте нет ответа, ответь 'Не знаю ответа на вопрос'. \n",
    "Используй максимум три предложения и будь точным но кратким.\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", \"\"\"Контекстная информация:\n",
    "\n",
    "        {context}\n",
    "        \n",
    "        Вопрос: {input}\t\t\n",
    "    \"\"\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#зададим 2 цепочки: для извлечения и переранжирования документов по вопросу и для получения итогового ответа\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "rag_chain = create_retrieval_chain(compression_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#теперь можем задавать вопрос\n",
    "answ = rag_chain.invoke({\"input\": \"Какое узкое место у архитектуры фон Неймана?\"})\n",
    "print(answ[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
